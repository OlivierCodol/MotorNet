{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Structure of State Tensors\n",
    "\n",
    "In this tutorial, we will go over the different types of states used in MotorNet, how they flow during simulation, how they are structured and what information they carry.\n",
    "\n",
    "Let's start by importing what we need.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already initialized using LOCAL initialization.\n",
      "All packages imported.\n",
      "tensorflow version: 2.9.1\n",
      "numpy version: 1.22.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "colab_env = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "colab_initialized = True if os.path.exists(\"MotorNet\") else False\n",
    "\n",
    "if colab_env and not colab_initialized:\n",
    "  !git clone https://github.com/OlivierCodol/MotorNet\n",
    "  sys.path.append('MotorNet')\n",
    "  print(\"Running cell using COLAB initialization...\")\n",
    "elif colab_env and colab_initialized:\n",
    "  print(\"Already initialized using COLAB initialization.\")\n",
    "else:\n",
    "  paths = [p for p in sys.path if os.path.exists(p)]\n",
    "  local_initialized = True if [p for p in paths if \"motornet\" in os.listdir(p)] else False\n",
    "  if local_initialized:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Already initialized using LOCAL initialization.\")\n",
    "  else:\n",
    "    path = [p for p in paths if p.__contains__(\"tutorials\")]\n",
    "    if len(path) != 1:\n",
    "      raise ValueError(\"Path to MotorNet could not be determined with certainty.\")\n",
    "    sys.path.append(os.path.dirname(path[:path.rfind('tutorials')]))\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Running cell using LOCAL initialization...\")\n",
    "\n",
    "\n",
    "import motornet as mn\n",
    "\n",
    "print('All packages imported.')\n",
    "print('tensorflow version: ' + tf.__version__)\n",
    "print('numpy version: ' + np.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# I. Types of States\n",
    "\n",
    "States are the main mean of communication between MotorNet objects and so they convey a wide variety of information.\n",
    "\n",
    "There are 7 states that will always be present regardless of the model being created.\n",
    "\n",
    "- Joint state\n",
    "- Cartesian state\n",
    "- Muscle state\n",
    "- Geometry state\n",
    "- Proprioceptive feedback state\n",
    "- Visual feedback state\n",
    "- Excitation\n",
    "\n",
    "Additionally, `Network` objects may have states associated with its functional units. For instance, Gated Recurrent Units (GRUs) or Long Short Term Memory (LSTM) units will have hidden activity that will need to get passed from timestep to timestep. Conversely, a simple multi-layer perceptron may not have any states associated with its computation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# II. State flow at runtime\n",
    "\n",
    "Below is an overview of where states are generated and updated in a MotorNet model, and how they flow from object to object.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "<img src=\"img/states.png\" alt=\"drawing\" width=\"600\"/>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above illustration, we can clearly see that `Muscle` objects generate muscle states, `Skeleton` objects generate joint and cartesian states, and `Plant` objects generate geometry states (though partially using `Skeleton` information). On the other hand, the `Network` object handles both proprioceptive and visual feedback states, and excitation states, on top of any additional network-related states that may be present if necessary for the employed network architecture.\n",
    "\n",
    "Excitation states can be subject to noise, but the excitation states returned by the model are the noise-free excitation states. This is because, when looking at that particular state, most users will be after the network output (noiseless excitation) rather than muscle input (noisy excitation).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Dimensionality of State tensors\n",
    "\n",
    "## III. 1. Plant States\n",
    "Let us create a plant, and then get initial states for a batch size of 7.\n",
    "We use a pre-built plant with 4 muscle, and then add a fifth muscle. The plant's skeleton has 2 degrees of freedom and evolves in a 2D cartesian space.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint state shape:  (7, 4)\n",
      "cartesian state shape:  (7, 4)\n",
      "muscle state shape:  (7, 4, 5)\n",
      "geometry state shape:  (7, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plant = mn.plants.ReluPointMass24()\n",
    "\n",
    "# adding a fifth muscle\n",
    "plant.add_muscle(path_fixation_body=[0, 1], path_coordinates=[[1, 0], [0, 0]], max_isometric_force=1)\n",
    "\n",
    "states = plant.get_initial_state(batch_size=7)\n",
    "labels = [\"joint state\", \"cartesian state\", \"muscle state\", \"geometry state\"]\n",
    "\n",
    "for label, state in zip(labels, states):\n",
    "  print(label + \" shape: \", state.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the example above it is fairly easy to see that for all states, the first dimension always corresponds to the batch size. We can also see that for the muscle and geometry states, the last dimension is always the number of muscles.\n",
    "\n",
    "The second dimension is the number of features of that state. For the joint state, this is the number of degrees of freedom times two (position and velocity). For the cartesian state, this is the dimensionality of the cartesian space (here 2D) times two (again, position and velocity).\n",
    "\n",
    "For the geometry state, this will always be musculotendon length, musculotendon velocity, and the moment of the muscle considered for each joint. Because there are two degrees of freedom here for the skeleton (two joints), there are two moments. Additionally, this information can be obtained by checking the `Plant` object's `geometry_state_name` attribute.\n",
    "\n",
    "For the muscle state, this depends on the muscle type being used. This information can be obtained by checking the `Muscle` object's `state_name` attribute. The `Muscle` object is directly accessible from the `Plant` object as demonstrated below.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0:  excitation/activation\n",
      "feature 1:  muscle length\n",
      "feature 2:  muscle velocity\n",
      "feature 3:  force\n"
     ]
    }
   ],
   "source": [
    "features = plant.muscle.state_name\n",
    "for n, feature in enumerate(features):\n",
    "  print(\"feature \" + str(n) + \": \", feature)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "And below, we fetch the geometry state names using the equivalent attribute for geometry at the `Plant` level.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0:  musculotendon length\n",
      "feature 1:  musculotendon velocity\n",
      "feature 2:  moment for joint 0\n",
      "feature 3:  moment for joint 1\n"
     ]
    }
   ],
   "source": [
    "features = plant.geometry_state_name\n",
    "for n, feature in enumerate(features):\n",
    "  print(\"feature \" + str(n) + \": \", feature)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III. 2. Network States\n",
    "\n",
    "Let's now look at states at the `Network` level. First, we build a `Network` from the same plant as earlier. One difference is that we will include feedback delays to proprioception and vision.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "plant = mn.plants.ReluPointMass24(proprioceptive_delay=0.03, visual_delay=0.09)\n",
    "\n",
    "plant.add_muscle(path_fixation_body=[0, 1], path_coordinates=[[1, 0], [0, 0]], max_isometric_force=1)  # adding a fifth muscle\n",
    "\n",
    "network = mn.nets.layers.GRUNetwork(plant=plant, n_units=50, kernel_regularizer=10**-6, name='network')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can print the state shapes from the `Network`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint position shape:  (4,)\n",
      "cartesian position shape:  (4,)\n",
      "muscle state shape:  (4, 5)\n",
      "geometry state shape:  (4, 5)\n",
      "proprioceptive feedback shape:  (10, 3)\n",
      "visual feedback shape:  (2, 9)\n",
      "excitation shape:  (5,)\n",
      "gru_hidden_0 shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "shapes = network.output_size\n",
    "names = network.output_names\n",
    "\n",
    "for name, shape in zip(names, shapes):\n",
    "  print(name + \" shape: \", shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that here, the batch size is omitted. This is because we are looking at symbolic tensors, and not eager tensors. This simply means that the first dimension is not displayed but in practice, at runtime, states will still have a first dimension representing batch size, and the shapes displayed here will be shifted one dimension to the right. We can also see that the `Plant` states are still available at this level.\n",
    "\n",
    "Following on, we have the proprioceptive and visual feedback states. Those are backlogs of elements from the muscle and cartesian states, respectively. For proprioception, the features are the muscle length for all five muscles, followed by their velocity, leading to `2 * 5 = 10` features. For vision, this is the cartesian position. Since this is a 2D cartesian space, the first dimension contains two entries. For both feedback states, the last dimension is as large as the backlog, and therefore depends on the delay declared when building the `Plant`. Here, we specified a proprioceptive delay of 30 ms, and the timesteps are 10 ms, resulting in 3 timesteps. For vision, the delay is 90 ms, resulting in 9 timesteps.\n",
    "\n",
    "The excitation shape depends on the number of muscles receiving descending drive from the `Newtork` object. Here, we have five muscles. Note the muscle type we use (ReLu muscles) requires only a scalar input, but if a muscle type requires more than one input, then the feature dimension of the excitation state would be multiplied by that.\n",
    "\n",
    "Finally, if `Network` states are required, they will be placed at the end of this list. Here, we only have one layer of 50 GRUs, so we have one 50-features GRU hidden state.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Initial States from Task objects\n",
    "\n",
    "Task objects can provide initial states from their `get_initial_state_layers` method. The list of states from this method has the same dimensionality, but the first dimension will be a `None` placeholder value for batch size."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint position shape:                   (None, 4)\n",
      "cartesian position shape:               (None, 4)\n",
      "muscle state shape:                     (None, 4, 5)\n",
      "geometry state shape:                   (None, 4, 5)\n",
      "proprioceptive feedback shape:          (None, 10, 3)\n",
      "visual feedback shape:                  (None, 2, 9)\n",
      "excitation shape:                       (None, 5)\n",
      "gru_hidden_0 shape:                     (None, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task = mn.tasks.RandomTargetReach(network=network)\n",
    "state0 = task.get_initial_state_layers()\n",
    "\n",
    "for name, state in zip(names, state0):\n",
    "  print(name + \" shape: \", \" \" * (30 - len(name)), state.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# V. States as returned from Model forward pass\n",
    "\n",
    "When doing a forward pass on a model, the model will output states as a result. These states take a specific value and so are not symbolic tensors, but instanciated tensors. The main point to keep in mind is that an additional dimension will be inserted in second position (right after the batch dimension), which corresponds to timesteps. Here we are doing a 100 timesteps simulation, and therefore that dimension will be of size 100. All the remaining dimensions will be pushed off to the right accordingly.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "inputs = task.get_input_dict_layers()\n",
    "\n",
    "rnn = tf.keras.layers.RNN(cell=network, return_sequences=True, name='RNN')\n",
    "states_out = rnn(inputs, initial_state=state0)\n",
    "\n",
    "model = mn.nets.MotorNetModel(inputs=[inputs, state0], outputs=states_out, name='model', task=task)\n",
    "model.compile(optimizer=tf.optimizers.Adam(clipnorm=1.), loss=task.losses, loss_weights=task.loss_weights)\n",
    "\n",
    "print(\"model compiled\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "[x, _, x0] = model.task.generate(n_timesteps=100, batch_size=7)\n",
    "results = model([x, x0], training=False)\n",
    "print(\"done\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint position                  (7, 100, 4)\n",
      "cartesian position              (7, 100, 4)\n",
      "muscle state                    (7, 100, 4, 5)\n",
      "geometry state                  (7, 100, 4, 5)\n",
      "proprioceptive feedback         (7, 100, 10, 3)\n",
      "visual feedback                 (7, 100, 2, 9)\n",
      "excitation                      (7, 100, 5)\n",
      "gru_hidden_0                    (7, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "  print(k, \" \" * (30 - len(k)), v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}