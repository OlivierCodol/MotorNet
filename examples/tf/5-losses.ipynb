{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create a Custom Loss\n",
    "\n",
    "In this tutorial, we will go over `Loss` objects, how they can be declared and assigned, and how to build a custom `Loss`.\n",
    "\n",
    "Let's start by importing what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cell using LOCAL initialization...\n",
      "\n",
      "All packages imported.\n",
      "tensorflow version: 2.13.0\n",
      "numpy version: 1.23.0\n",
      "motornet version: 0.1.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython import get_ipython\n",
    "\n",
    "\n",
    "colab_env = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "colab_initialized = True if os.path.exists(\"MotorNet\") else False\n",
    "\n",
    "if colab_env and not colab_initialized:\n",
    "  !pip install motornet==0.1.5\n",
    "  sys.path.append('MotorNet')\n",
    "  print(\"Running cell using COLAB initialization...\")\n",
    "elif colab_env and colab_initialized:\n",
    "  print(\"Already initialized using COLAB initialization.\")\n",
    "else:\n",
    "  paths = [p for p in sys.path if os.path.exists(p)]\n",
    "  local_initialized = True if [p for p in paths if \"motornet\" in os.listdir(p)] else False\n",
    "  if local_initialized:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Already initialized using LOCAL initialization.\")\n",
    "  else:\n",
    "    path = [p for p in paths if p.__contains__(\"examples\")]\n",
    "    if len(path) != 1:\n",
    "      raise ValueError(\"Path to MotorNet could not be determined with certainty.\")\n",
    "    else:\n",
    "       path = path[0]\n",
    "    sys.path.append(os.path.dirname(path[:path.rfind('examples')]))\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Running cell using LOCAL initialization...\")\n",
    "\n",
    "\n",
    "import motornet_tf as mn\n",
    "\n",
    "\n",
    "print('\\nAll packages imported.')\n",
    "print('tensorflow version: ' + tf.__version__)\n",
    "print('numpy version: ' + np.__version__)\n",
    "print('motornet version: ' + mn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# I. Losses in Task Objects\n",
    "\n",
    "## I. 1. Printing out currently declared losses\n",
    "\n",
    "The simplest way to handle losses is via `Task` objects. Note that declaring losses via `Task` objects is not the only viable way, but this is easier, as otherwise we would have to manually do all the things that `add_loss` does automatically for us. Also, this may result in misleading (shuffled) loss labels when printing progress bars at runtime because `tensorflow` models (`tf.keras.Model`) do not maintain loss label orders properly for some reason. Adding losses to the task object will make it available to our curstom-made `tf.keras.Model` subclass, which is `mn.nets.MotorNetModel`. In `MotorNetModel` instances, the losses available in `Task` subclasses will be re-ordered properly at initialization to avoid the parent class `tf.keras.Model` reshuffling the labels in a wrong order.\n",
    "\n",
    "Here, we import a pre-built `Task` object called `CentreOutReach`. Some losses are already included by default and we can print them out using `print_losses`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGNED OUTPUT: cartesian position\n",
      "-----------------------------------\n",
      "loss function:  <motornet_tf.nets.losses.PositionLoss object at 0x13db18130>\n",
      "loss weight:    1.0\n",
      "loss name:      position\n",
      "Compounded:     NO\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: muscle state\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxActivationLoss object at 0x13db180a0>\n",
      "loss weight:    5\n",
      "loss name:      l2_xdx_activation\n",
      "Compounded:     NO\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: gru_hidden_0\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxRegularizer object at 0x13db18040>\n",
      "loss weight:    0.1\n",
      "loss name:      gru_regularizer\n",
      "Compounded:     NO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plant = mn.plants.ReluPointMass24()\n",
    "network = mn.nets.layers.GRUNetwork(plant=plant, n_units=50, kernel_regularizer=10**-6, name='network')\n",
    "\n",
    "task = mn.tasks.CentreOutReach(network=network)\n",
    "\n",
    "task.print_losses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## I. 2. Declaring new losses via the Task object\n",
    "\n",
    "Losses can be declared via the `Task` object using the `add_loss` method. Feel free to check the Reference Manual online for more details on that method, but this is briefly reproduced here for convenience. See below the arguments the `add_loss` method can take.\n",
    "\n",
    "- `loss`: A `tensorflow.python.keras.losses.Loss` object class or subclass. `Loss` subclasses specific to `MotorNet` are also available in the `motornet.nets.losses` module.\n",
    "\n",
    "- `assigned_output`: A string indicating the output state that the loss will be applied to. This should correspond to an output name from the `Network` object instance passed at initialization. The output names can be retrieved via the `motornet.nets.layers.Network.output_names` attribute.\n",
    "\n",
    "- `loss_weight`: [Optional], A float indicating the weight of the loss when all contributing losses are added to the total loss. Default: is `1.0`.\n",
    "\n",
    "- `name`: [Optional], A string indicating the name (label) to give to the loss object. This is used to print, plot, and save losses during training.\n",
    "\n",
    "If we add a loss using the `add_loss` method and print the losses again, we can see that the new loss is now included in the `Task` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGNED OUTPUT: cartesian position\n",
      "-----------------------------------\n",
      "loss function:  <motornet_tf.nets.losses.PositionLoss object at 0x13db18130>\n",
      "loss weight:    1.0\n",
      "loss name:      position\n",
      "Compounded:     YES\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: cartesian position\n",
      "-----------------------------------\n",
      "loss function:  <motornet_tf.nets.losses.PositionLoss object at 0x107436200>\n",
      "loss weight:    1.0\n",
      "loss name:      position\n",
      "Compounded:     YES\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: muscle state\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxActivationLoss object at 0x13db180a0>\n",
      "loss weight:    5\n",
      "loss name:      l2_xdx_activation\n",
      "Compounded:     NO\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: gru_hidden_0\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxRegularizer object at 0x13db18040>\n",
      "loss weight:    0.1\n",
      "loss name:      gru_regularizer\n",
      "Compounded:     NO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task.add_loss(loss=mn.nets.losses.PositionLoss(), assigned_output=\"cartesian position\")\n",
    "task.print_losses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that \"Compounded\" indicates if the loss shares an assigned output with another loss. This is because several losses can be assigned to the same output state. If this is the case, then their loss value will be added together, weighted by the loss weight of each contributing loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# II. Creating a Custom Loss Object\n",
    "\n",
    "The Loss objects passed to the `loss`argument in the `add_loss` methods are subclasses of `tensorflow.python.keras.losses.LossFunctionWrapper` objects from TensorFlow.\n",
    "\n",
    "First, we need a loss function, which must take at least a `y_true` and `y_pred` input, in that order. Note that those two arguments must be present even if they are not used. Extra arguments may then be passed as well after this. This function must contain the loss formula leading to the penalty used for training the network, and return said penalty.\n",
    "\n",
    "When calling the base class at initialization, the loss function must be specified as the first input, followed by optional arguments such as the name of the function or the reduction method. Finally, extra arguments to be passed the loss function must be passed last.\n",
    "\n",
    "For more details about the reduction methods to use, feel free to check this custom training [tutorial](https://www.tensorflow.org/tutorials/distribute/custom_training) from TensorFlow.\n",
    "For more details on how to subclass `LossFunctionWrapper` objects, feel free to check the TensorFlow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# importing dependencies\n",
    "from tensorflow.python.keras.losses import LossFunctionWrapper\n",
    "from tensorflow.python.keras.utils import losses_utils\n",
    "\n",
    "\n",
    "# creating loss function\n",
    "def _l2_activation_loss(y_true, y_pred, extra_arg_1, extra_arg_2):\n",
    "    activation = tf.slice(y_pred, [0, 0, 0, 0], [-1, -1, 1, -1])\n",
    "    return extra_arg_1 * tf.reduce_mean(activation ** 2) + extra_arg_2\n",
    "\n",
    "\n",
    "# creating loss subclass\n",
    "class L2ActivationLoss(LossFunctionWrapper):\n",
    "\n",
    "    def __init__(self, extra_arg_1, extra_arg_2=1, name='l2_activation', reduction=losses_utils.ReductionV2.AUTO):\n",
    "\n",
    "        super().__init__(_l2_activation_loss, name=name, reduction=reduction, extra_arg_1=extra_arg_1, extra_arg_2=extra_arg_2)\n",
    "\n",
    "        # one can add the extra arguments passed as attributes if desired\n",
    "        self.extra_arg_1 = extra_arg_1\n",
    "        self.extra_arg_2 = extra_arg_2\n",
    "\n",
    "\n",
    "# creating loss instance\n",
    "new_loss_object = L2ActivationLoss(extra_arg_1=1, name='example_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "We can now assign our newly-made custom loss to a `Network` state of our choosing using the process described in section I.2. above. For instance, for the `excitation` state:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGNED OUTPUT: cartesian position\n",
      "-----------------------------------\n",
      "loss function:  <motornet_tf.nets.losses.PositionLoss object at 0x13db18130>\n",
      "loss weight:    1.0\n",
      "loss name:      position\n",
      "Compounded:     YES\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: cartesian position\n",
      "-----------------------------------\n",
      "loss function:  <motornet_tf.nets.losses.PositionLoss object at 0x107436200>\n",
      "loss weight:    1.0\n",
      "loss name:      position\n",
      "Compounded:     YES\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: muscle state\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxActivationLoss object at 0x13db180a0>\n",
      "loss weight:    5\n",
      "loss name:      l2_xdx_activation\n",
      "Compounded:     NO\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: excitation\n",
      "---------------------------\n",
      "loss function:  <__main__.L2ActivationLoss object at 0x1074350c0>\n",
      "loss weight:    1.0\n",
      "loss name:      example_loss\n",
      "Compounded:     NO\n",
      "\n",
      "\n",
      "ASSIGNED OUTPUT: gru_hidden_0\n",
      "-----------------------------\n",
      "loss function:  <motornet_tf.nets.losses.L2xDxRegularizer object at 0x13db18040>\n",
      "loss weight:    0.1\n",
      "loss name:      gru_regularizer\n",
      "Compounded:     NO\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task.add_loss(loss=new_loss_object, assigned_output='excitation')\n",
    "task.print_losses()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
