{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a custom task and network\n",
    "\n",
    "The purpose of this notebook is to create a network to control a plant, and to declare a task that the network can learn through the optimization process. The actual optimization process, and how to save and re-load a network will be discussed in another notebook.\n",
    "\n",
    "For how to build a plant from scratch, feel free to look up the `1-build-plant.ipynb` notebook.\n",
    "\n",
    "Let's start by importing what we need.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Already initialized using LOCAL initialization.\n",
      "All packages imported.\n",
      "tensorflow version: 2.9.0\n",
      "numpy version: 1.22.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "colab_env = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "colab_initialized = True if os.path.exists(\"MotorNet\") else False\n",
    "\n",
    "if colab_env and not colab_initialized:\n",
    "  !git clone https://github.com/OlivierCodol/MotorNet\n",
    "  sys.path.append('MotorNet')\n",
    "  print(\"Running cell using COLAB initialization...\")\n",
    "elif colab_env and colab_initialized:\n",
    "  print(\"Already initialized using COLAB initialization.\")\n",
    "else:\n",
    "  paths = [p for p in sys.path if os.path.exists(p)]\n",
    "  local_initialized = True if [p for p in paths if \"motornet\" in os.listdir(p)] else False\n",
    "  if local_initialized:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Already initialized using LOCAL initialization.\")\n",
    "  else:\n",
    "    path = [p for p in paths if p.__contains__(\"tutorials\")]\n",
    "    if len(path) != 1:\n",
    "      raise ValueError(\"Path to MotorNet could not be determined with certainty.\")\n",
    "    sys.path.append(os.path.dirname(path[:path.rfind('tutorials')]))\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    print(\"Running cell using LOCAL initialization...\")\n",
    "\n",
    "\n",
    "import motornet as mn\n",
    "\n",
    "print('All packages imported.')\n",
    "print('tensorflow version: ' + tf.__version__)\n",
    "print('numpy version: ' + np.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# I. Introduction\n",
    "\n",
    "Since the purpose of this notebook is not to show how to build a plant, we will use a pre-built plant that comes with the `motornet` toolbox. This is a 4-muscles point mass plant, with `ReluMuscle` actuators.\n",
    "\n",
    "We will also use the default `motornet` network, which is a GRU network. Since we only specify an integer (rather than a list of integers) for `n_units`, this will end up being a one-layer GRU network.\n",
    "\n",
    "Generally speaking, the objects we create follow the hierarchical structure illustrated below.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "<img src=\"img/hierarchy.png\" alt=\"drawing\" width=\"500\"/>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "plant = mn.plants.ReluPointMass24()\n",
    "network = mn.nets.layers.GRUNetwork(plant=plant, n_units=50, kernel_regularizer=10**-6, name='network')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Subclassing a Task object\n",
    "\n",
    "Let us go over a simple subclassing process to create a custom task.\n",
    "\n",
    "\n",
    "### II. 1. Initialization of the Task subclass\n",
    "The base class for tasks is `mn.tasks.Task`, so we will make the custom task inherit from that base class. We can then define a `__name__` for the class, and declare the losses in the `__init__` method using a `self.add_loss` method that is inherited from the base class.\n",
    "\n",
    "Note that declaring losses is not mandatory for the simulation to run, but this is easier, as otherwise we would have to manually do all the things that `add_loss` does automatically for us. Also this may result in misleading (shuffled) loss labels when printing progress bars at runtime because `tensorflow` models (`tf.keras.Model`) do not maintain loss label orders properly for some reason. Adding losses to the task object will make it available to our curstom-made `tf.keras.Model` subclass, which is `mn.nets.MotorNetModel`. In `MotorNetModel` the losses available in `Task` subclasses will be re-ordered properly to avoid the parent class `tf.keras.Model` reshuffling the labels in a wrong order.\n",
    "\n",
    "The `add_loss` method takes three arguments:\n",
    "- `assigned_output` should be a string matching one of the keys of the `MotorNetModel`'s output dictionary. Of note, each key corresponds to a state of the model. In its current version, `motornet` only allows one loss per output key.\n",
    "- `loss` should pass a loss object, either custom-made or from the `mn.nets.losses` module.\n",
    "- `loss_weight` is a scalar that defines the weight of the loss in the global loss that the network will optimize at runtime.\n",
    "\n",
    "\n",
    "### II. 2. Generating inputs\n",
    "We can next define the `task.generate` method. It should take as inputs:\n",
    "- `batch_size`\n",
    "- `n_timesteps`\n",
    "\n",
    "If desired, it can also take `**kwargs` inputs.\n",
    "\n",
    "It should produce as output a list containing three items, in the order below:\n",
    "- A dictionary containing the inputs to the network.\n",
    "- The targets that will be passed to the network (the `y`).\n",
    "- The initial states to the network.\n",
    "\n",
    "\n",
    "#### II. 2. a. Input dictionary\n",
    "The input dictionary only requires a \"inputs\" key. The value assigned to that key will be passed as-is as input to the network for a forward pass. So is content is essentially up to the user, according to what the user wishes the network to receive as input information. Typically, for a reaching movement, this could be the target's position in cartesian coordinates. If a delayed reach is desired, one could consider adding a go cue as well.\n",
    "\n",
    "Of note, the first dimension (rows) should always be  `batch_size` and the second dimension (columns) should always be the number of timesteps for the reach. This is true for any value in that dictionary, not just for the value associated with the \"inputs\" key.\n",
    "\n",
    "Other notable keys one may add are \"joint_load\" and \"endpoint_load\". These would be transmitted to the plant by the network. If one wishes to add more keys to the input dictionary, it would be required to subclass the network to implement appropriate handling of these custom-made keys in the `call` method of the network.\n",
    "\n",
    "The flexibility from using a dictionary as input is the reason we decided to use them. Note however that generally, `tensorflow` models can accept other forms of inputs, such as simple arrays, though our `motornet` model does not.\n",
    "\n",
    "\n",
    "#### II. 2. b. Targets\n",
    "The target values that the plant should produce, and that will be passed to the loss functions. In `tensorflow` nomenclature, this is sometimes referred to as the `y_true`, to which the `y_pred` is compared.\n",
    "In practice this could be the position of the target for a reaching movement. If a delayed movement is desired, it could be the starting position until the go cue time, and the target position afterwards.\n",
    "\n",
    "\n",
    "#### II. 2. c. Initial states\n",
    "The value of the initial states at simulation start. These can be obtained from the `task.get_initial_state(batch_size=batch_size)` method. If a pre-defined starting position is desired, one can pass an optional `joint_state` argument to this method as well.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task subclass built.\n",
      "\n",
      "Dictionary content:\n",
      "\tinputs shape :-->  (5, 10, 2)\n",
      "\tendpoint_load shape :-->  (5, 10, 2)\n",
      "\n",
      "targets shape :-->  (5, 10, 4) \n",
      "\n",
      "initial states shape:\n",
      "\t (5, 4)\n",
      "\t (5, 4)\n",
      "\t (5, 4, 4)\n",
      "\t (5, 4, 4)\n",
      "\t (5, 8, 1)\n",
      "\t (5, 2, 1)\n",
      "\t (5, 4)\n",
      "\t (5, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class RandomTargetReachWithLoads(mn.tasks.Task):\n",
    "    def __init__(self, network, endpoint_load: float, **kwargs):\n",
    "        super().__init__(network, **kwargs)\n",
    "        self.__name__ = 'RandomTargetReachWithLoads'\n",
    "        self.endpoint_load = endpoint_load\n",
    "\n",
    "        # losses\n",
    "        max_iso_force = self.network.plant.muscle.max_iso_force\n",
    "        c_loss = mn.nets.losses.PositionLoss()\n",
    "        m_loss = mn.nets.losses.L2ActivationLoss(max_iso_force=max_iso_force)\n",
    "        self.add_loss(assigned_output='cartesian position', loss=c_loss, loss_weight=1.)\n",
    "        self.add_loss(assigned_output='muscle state', loss=m_loss, loss_weight=.2)\n",
    "\n",
    "    def generate(self, batch_size, n_timesteps, **kwargs):\n",
    "        validation = kwargs.get(\"validation\", False)\n",
    "        if not validation:\n",
    "            init_states = self.get_initial_state(batch_size=batch_size)\n",
    "        else:\n",
    "            joint_state = tf.zeros((batch_size, self.network.plant.space_dim))\n",
    "            init_states = self.get_initial_state(batch_size=batch_size, joint_state=joint_state)\n",
    "        goal_states_j = self.network.plant.draw_random_uniform_states(batch_size=batch_size)\n",
    "        goal_states = self.network.plant.joint2cartesian(goal_states_j)\n",
    "        targets = self.network.plant.state2target(state=goal_states, n_timesteps=n_timesteps).numpy()\n",
    "        endpoint_load = tf.constant(self.endpoint_load, shape=(batch_size, n_timesteps, 2))\n",
    "        inputs = {\"inputs\": targets[:, :, :self.network.plant.space_dim], \"endpoint_load\": endpoint_load}\n",
    "        return [inputs, targets, init_states]\n",
    "\n",
    "\n",
    "task = RandomTargetReachWithLoads(network=network, endpoint_load=3.)\n",
    "print(\"Task subclass built.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "L = task.generate(batch_size=5, n_timesteps=10, validation=True)\n",
    "\n",
    "print(\"Dictionary content:\")\n",
    "for k, v in L[0].items():\n",
    "    print(\"\\t\" + k + \" shape :--> \", v.shape)\n",
    "\n",
    "print(\"\\ntargets shape :--> \", L[1].shape, \"\\n\")\n",
    "\n",
    "print(\"initial states shape:\")\n",
    "for elem in L[2]:\n",
    "    print(\"\\t\", elem.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In `tensorflow`, creating a model requires declaring `tf.keras.layers.Input` layers that will handle the input and initial state data. Creating these `Input` layers mainly require to declare the shape of the arrays that will be passed through. The `Task` class should provide those using the `get_input_dict_layers` and `get_initial_state_layers` methods.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs :-->  KerasTensor(type_spec=TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='inputs'), name='inputs', description=\"created by layer 'inputs'\")\n",
      "endpoint_load :-->  KerasTensor(type_spec=TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='endpoint_load'), name='endpoint_load', description=\"created by layer 'endpoint_load'\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = task.get_input_dict_layers()\n",
    "for k, v in inputs.items():\n",
    "    print(k + \" :--> \", v)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='joint0'), name='joint0', description=\"created by layer 'joint0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='cartesian0'), name='cartesian0', description=\"created by layer 'cartesian0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4), dtype=tf.float32, name='muscle0'), name='muscle0', description=\"created by layer 'muscle0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4), dtype=tf.float32, name='geometry0'), name='geometry0', description=\"created by layer 'geometry0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 8, 1), dtype=tf.float32, name='proprio_feedback0'), name='proprio_feedback0', description=\"created by layer 'proprio_feedback0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='visual_feedback0'), name='visual_feedback0', description=\"created by layer 'visual_feedback0'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='excitation'), name='excitation', description=\"created by layer 'excitation'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='gru_hidden_0_0'), name='gru_hidden_0_0', description=\"created by layer 'gru_hidden_0_0'\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state0 = task.get_initial_state_layers()\n",
    "\n",
    "for s in state0:\n",
    "    print(s)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Building the network\n",
    "\n",
    "In `tensorflow`, recurrent neural networks need to be wrapped around a `tf.keras.layers.RNN` layer (see [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN)). We set `return_sequences` to `True` to allow for all timesteps to be returned, rather than only the final step.\n",
    "\n",
    "Next, we build the model using our `tf.keras.Model` subclass, `mn.nets.MotorNetModel`. The `MotorNetModel` class takes the same input as its parent class, as well as the `Task` object, which must be declared. It returns the same outputs as its parent class.\n",
    "\n",
    "The purpose of subclassing `tf.keras.Model` is mainly to have custom saving and loading methods that are adequate to the models we created.\n",
    "\n",
    "Finally, we can compile the model, using the losses held in the `Task` object.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " endpoint_load (InputLayer)     [(None, None, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " inputs (InputLayer)            [(None, None, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " joint0 (InputLayer)            [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " cartesian0 (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " muscle0 (InputLayer)           [(None, 4, 4)]       0           []                               \n",
      "                                                                                                  \n",
      " geometry0 (InputLayer)         [(None, 4, 4)]       0           []                               \n",
      "                                                                                                  \n",
      " proprio_feedback0 (InputLayer)  [(None, 8, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " visual_feedback0 (InputLayer)  [(None, 2, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " excitation (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " gru_hidden_0_0 (InputLayer)    [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " RNN (RNN)                      {'joint position':   9804        ['endpoint_load[0][0]',          \n",
      "                                (None, None, 4),                  'inputs[0][0]',                 \n",
      "                                 'cartesian positio               'joint0[0][0]',                 \n",
      "                                n': (None, None, 4)               'cartesian0[0][0]',             \n",
      "                                , 'muscle state': (               'muscle0[0][0]',                \n",
      "                                None, None, 4, 4),                'geometry0[0][0]',              \n",
      "                                 'geometry state':                'proprio_feedback0[0][0]',      \n",
      "                                (None, None, 4, 4),               'visual_feedback0[0][0]',       \n",
      "                                 'proprioceptive fe               'excitation[0][0]',             \n",
      "                                edback': (None, Non               'gru_hidden_0_0[0][0]']         \n",
      "                                e, 8, 1),                                                         \n",
      "                                 'visual feedback':                                               \n",
      "                                 (None, None, 2, 1)                                               \n",
      "                                , 'excitation': (No                                               \n",
      "                                ne, None, 4),                                                     \n",
      "                                 'gru_hidden_0': (N                                               \n",
      "                                one, None, 50)}                                                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,804\n",
      "Trainable params: 9,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnn = tf.keras.layers.RNN(cell=network, return_sequences=True, name='RNN')\n",
    "states_out = rnn(inputs, initial_state=state0)\n",
    "\n",
    "model = mn.nets.MotorNetModel(inputs=[inputs, state0], outputs=states_out, name='model', task=task)\n",
    "model.compile(optimizer=tf.optimizers.Adam(clipnorm=1.), loss=task.losses, loss_weights=task.loss_weights)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Finally, we can generate inputs with a single line using the `task.generate` method, and run the model like one would any `tensorflow` model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 100ms/step - loss: 0.7347 - position_loss: 0.7347 - l2_activation_loss: 4.9073e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_t = 100\n",
    "n_batches = 4\n",
    "batch_size = 32\n",
    "\n",
    "[inputs, targets, init_states] = task.generate(n_timesteps=n_t, batch_size=n_batches * batch_size)\n",
    "cb = model.fit(x=[inputs, init_states], y=targets, verbose=1, epochs=1, batch_size=batch_size, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}